\section{Markov Chains}
\begin{framed}
    A \textbf{Markov Chain} over $\sS \defeq \{0, \dots, n-1\}$, is a sequence $(X_t)_{t \in \Nat_0} \in \sS$, such that the \textbf{Markov property}: $X_{t+1} \perp X_{0:t-1} \mid X_t$ is satisfied. 
\end{framed}
It is \textbf{time-homogeneous} if there is a \textbf{transition function}: $p(x' \mid x) \defeq \Pr{X_{t+1} = x' \mid X_t = x}$, with \textbf{transition matrix} as $\left(x_j \mid x_i \right)_{i, j = 1}^n$. Each row sums up to 1. \\
The state of a MC at $t$ is a probability distribution $\vq_t \in \R^{1 \times \card{\sS}}$. We can write: $\vq_{t+k} = \vq_t \mP^k$.
\begin{framed}
    A distribution $\pi$ is \textbf{stationary} iff\\ $\pi(x) = \sum_{x' \in S} p(x \mid x') \pi(x')$ equivalently $\vpi = \vpi \mP$
\end{framed}
An MC is \textbf{irreducible} if every state is reachable from any state with positive probability.
\begin{framed}
    MC is \textbf{ergodic} $\iff$ $\exists t$ s.t. every state
    can be reached from every other state in exactly $t$ steps $\iff$
    for some $t \in \Nat_0$ all entries of $\mP^t$ are strictly positive
    $\iff$ MC is irreducible and aperiodic.
\end{framed}
Irreducible MC $\rightarrow$ ergodic MC use: $\mP' = \frac{1}{2}\mP + \frac{1}{2}\mI$
\begin{framed}
    An ergodic MC has a unique stat. dist. $\pi$ (with full support) and $\lim_{t\to\infty} q_t = \pi$, for any $q_0$.
\end{framed}
\begin{framed}
    An MC satisfies \textbf{detailed balance equation} w.r.t. $\pi$ iff $\pi(x) p(x' \mid x) = \pi(x') p(x \mid x')$, for any $x, x' \in S$. Such an MC is \textbf{reversible} w.r.t. $\pi$.
\end{framed}
If MC is reversible w.r.t. $\pi$, then $\pi$ is a stat. dist.
\begin{framed}
    \textbf{Ergodic theorem} For an ergodic MC with stationary dist. $\pi$ and $f : \sS \to \R$: \\
    $\frac{1}{n} \sum_{i=1}^n f(x_i) \almostsurely \sum_{x \in S} \pi(x) f(x) = \E[x \sim \pi]{f(x)}$, for $n\to\infty$ where $x_i \sim X_i \mid x_{i-1}$.
\end{framed}
\textbf{Acceptance distribution (Metropolis-Hastings)}: $\Bern{\alpha(\vxp \mid \vx)}$ where $\alpha(\vxp \mid \vx) \defeq \min \braces*{1, \frac{q(\vxp) r(\vx \mid \vxp)}{q(\vx) r(\vxp \mid \vx)}}$ yields a Markov chain with stationary distribution $p(\vx) = \frac{1}{Z} q(\vx)$.
\includegraphics[width=0.98\linewidth, trim={0 0 5cm 0}]{images/Metropiolis_Hasting.png}
\includegraphics[width=0.98\linewidth]{images/Gibbs_Sampling.png} 
Simulates MC w/ stationary dist. $p(\vx)$. \\
Interpret posterior as \textbf{Gibbs dist.} $p(\vx) = \frac{1}{Z} \exp(- f(\vx))$. Energy function $f$: convex $\Rightarrow$ Gibbs dist. \textbf{log-concave}. Always: $\alpha(\vxp \mid \vx) = \min \braces*{1, \frac{r(\vx \mid \vxp)}{r(\vxp \mid \vx)} \exp(f(\vx) - f(\vxp))}$. \\
$p(\vtheta \mid \vx_{1:n}, y_{1:n}) = \frac{1}{Z} p(\vtheta) p(y_{1:n} \mid \vx_{1:n}, \vtheta) = $\\
$ \frac{1}{Z} \exp(\log p(\vtheta) p(y_{1:n} \mid \vx_{1:n}, \vtheta)) = \frac{1}{Z} \exp(-f(\vtheta))$.
\begin{framed}
    \textbf{Langevin Dynamics}: converges for $\vtheta_t \sim t^{-\nicefrac{1}{3}}$. \\
    $\vtheta_{t+1} = \vtheta_t - \eta_t \nabla f(\vtheta_t) + \varepsilon_t, \quad \varepsilon \sim \N{\vzero}{\mI}$ \\
\end{framed}
Alt.: $\vtheta \mathrel{+}= \eta (\nabla \log p(\vtheta) + \Sigma_i \nabla \log p(y_i \mid \vx_i, \vtheta)) + \varepsilon$.